"""Agent planner for query analysis and action planning."""

import logging
from enum import Enum
from typing import Optional

from openai import OpenAI
from pydantic import BaseModel, Field

from src.core.config import settings

logger = logging.getLogger(__name__)


class ActionType(str, Enum):
    """Types of actions the agent can take."""

    GREETING = "greeting"
    RAG_QUERY = "rag_query"
    GENERAL_CHAT = "general_chat"
    CLARIFICATION = "clarification"


class Plan(BaseModel):
    """Plan generated by the agent."""

    action: ActionType = Field(description="The type of action to take")
    reasoning: str = Field(description="Why this action was chosen")
    needs_retrieval: bool = Field(description="Whether RAG retrieval is needed")
    suggested_response: Optional[str] = Field(
        default=None,
        description="Suggested response for simple queries (greetings, clarifications)"
    )


class Agent:
    """
    Agent that analyzes queries and plans appropriate actions.

    This agent uses an LLM to understand user intent and decide whether
    to use RAG retrieval, provide a direct response, or ask for clarification.
    """

    def __init__(
        self,
        api_key: Optional[str] = None,
        model_name: str = "gpt-4o-mini",
    ):
        """
        Initialize the agent.

        Args:
            api_key: OpenAI API key (uses settings.openai_api_key if not provided)
            model_name: Model to use for planning
        """
        self.api_key = api_key or settings.openai_api_key
        self.model_name = model_name

    def _get_client(self) -> OpenAI:
        """Get OpenAI client."""
        return OpenAI(api_key=self.api_key)

    def plan(self, query: str, context: Optional[str] = None) -> Plan:
        """
        Analyze a query and create an action plan.

        Args:
            query: User's query
            context: Optional conversation context

        Returns:
            Plan object with action type and details
        """
        client = self._get_client()

        # Build planning prompt
        system_message = """You are an intelligent agent that analyzes user queries for a RAG system.

Your job is to determine the query type:

Query types:
- GREETING: Simple greetings, thanks, goodbyes (no retrieval)
- RAG_QUERY: Any informational question (retrieval attempted, falls back to general knowledge if no documents found)
- CLARIFICATION: Ambiguous queries needing clarification (no retrieval)

Default to RAG_QUERY for questions - the system will handle fallback to general knowledge."""

        user_prompt = f"""Query: "{query}"

Analyze this query and create a plan."""

        if context:
            user_prompt = f"""Previous context: {context}

{user_prompt}"""

        logger.info(f"Planning action for query: '{query[:50]}...'")

        try:
            # Use structured output for planning
            completion = client.beta.chat.completions.parse(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": user_prompt},
                ],
                response_format=Plan,
                temperature=0.3,
            )

            plan = completion.choices[0].message.parsed

            logger.info(
                f"Plan created: action={plan.action}, "
                f"needs_retrieval={plan.needs_retrieval}, "
                f"reasoning={plan.reasoning[:100]}..."
            )

            return plan

        except Exception as e:
            logger.error(f"Error creating plan: {e}")
            # Fallback: assume it's a RAG query
            return Plan(
                action=ActionType.RAG_QUERY,
                reasoning=f"Fallback plan due to error: {str(e)}",
                needs_retrieval=True,
                suggested_response=None,
            )
